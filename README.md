# ğŸ™ï¸ Alloy Voice Assistant

**Multimodaler Voice-Assistant** mit lokaler Speech-to-Text (Whisper), Vision (Webcam), LLM-Agent (GPT-4o/Ollama) und Text-to-Speech (Piper). UnterstÃ¼tzt Russisch und Deutsch mit Hotkey-Umschaltung.

---

## ğŸ¯ Features

- âœ… **Lokale Speech-to-Text** (OpenAI Whisper)
- âœ… **Lokale Text-to-Speech** (Piper, GPU-beschleunigt)
- âœ… **Vision** (Webcam-Integration, erkennt Objekte/Szenen)
- âœ… **LLM-Agent** mit Tools:
  - ğŸŒ Web-Suche (DuckDuckGo, kostenlos)
  - ğŸŒ¤ï¸ Wetter (wttr.in API, kostenlos)
  - ğŸ• Aktuelle Uhrzeit/Datum
  - ğŸ§® Taschenrechner (sicheres `eval`)
- âœ… **Mehrsprachig** (Russisch/Deutsch, live umschaltbar)
- âœ… **Chat-History** (Kontext Ã¼ber mehrere Fragen)
- âœ… **Offline-fÃ¤hig** (mit Ollama statt OpenAI)

---

## ğŸ“‹ Voraussetzungen

### Hardware
- **Windows 10/11** (64-bit) oder **Linux**
- **Webcam** (USB oder integriert)
- **Mikrofon** (USB oder integriert)
- **GPU** (optional, empfohlen): NVIDIA mit CUDA 11.8+

### Software
- **Python 3.10 oder 3.11** (3.12+ nicht getestet)
- **Git** (fÃ¼r Klonen des Repos)
- **CUDA Toolkit 11.8+** (optional, fÃ¼r GPU-Beschleunigung)

---

## ğŸš€ Installation

### 1. Repository klonen

```bash
git clone https://github.com/yourusername/alloy-voice-assistant.git
cd alloy-voice-assistant
```

---

### 2. Python Virtual Environment erstellen

**Git Bash / Linux:**
```bash
python -m venv .venv
source .venv/Scripts/activate  # Git Bash (Windows)
source .venv/bin/activate      # Linux/macOS
```

**PowerShell:**
```powershell
python -m venv .venv
.venv\Scripts\Activate.ps1
```

**PrÃ¼fen:**
```bash
which python  # sollte .venv/Scripts/python zeigen
```

---

### 3. Dependencies installieren

```bash
pip install --upgrade pip setuptools wheel
pip install -r requirements.txt
```

**Falls `pyaudio` Fehler wirft (Windows):**
```bash
pip install pipwin
pipwin install pyaudio
```

**Linux (Ubuntu/Debian):**
```bash
sudo apt install portaudio19-dev python3-pyaudio ffmpeg
pip install -r requirements.txt
```

---

### 4. TTS-Modelle herunterladen

#### **Russisch (Irina, weiblich)**
```bash
mkdir -p models/piper/ru/ru_RU/irina/medium
cd models/piper/ru/ru_RU/irina/medium

curl -LO https://huggingface.co/rhasspy/piper-voices/resolve/main/ru/ru_RU/irina/medium/ru_RU-irina-medium.onnx
curl -LO https://huggingface.co/rhasspy/piper-voices/resolve/main/ru/ru_RU/irina/medium/ru_RU-irina-medium.onnx.json

cd ../../../../..
```

#### **Deutsch (Eva_K, weiblich)**
```bash
mkdir -p models/piper/de/de_DE/eva_k/x_low
cd models/piper/de/de_DE/eva_k/x_low

curl -LO https://huggingface.co/rhasspy/piper-voices/resolve/main/de/de_DE/eva_k/x_low/de_DE-eva_k-x_low.onnx
curl -LO https://huggingface.co/rhasspy/piper-voices/resolve/main/de/de_DE/eva_k/x_low/de_DE-eva_k-x_low.onnx.json

cd ../../../../..
```

**Alternative deutsche Stimmen:**
- **Thorsten (mÃ¤nnlich)**: `de/de_DE/thorsten/medium`
- **Karlsson (mÃ¤nnlich, tief)**: `de/de_DE/karlsson/low`

Alle Stimmen: https://huggingface.co/rhasspy/piper-voices/tree/main

---

### 5. `.env` Datei erstellen

```bash
cp .env.example .env
nano .env  # oder Editor deiner Wahl (VS Code, Notepad++)
```

**Minimal-Konfiguration:**
```properties
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4o

DEFAULT_LANGUAGE=ru
PIPER_MODEL_RU=models/piper/ru/ru_RU/irina/medium/ru_RU-irina-medium.onnx
PIPER_MODEL_DE=models/piper/de/de_DE/eva_k/x_low/de_DE-eva_k-x_low.onnx
WHISPER_MODEL=base
CAMERA_INDEX=0
DISABLE_TTS=0
```

**Wichtig:** Ersetze `OPENAI_API_KEY` mit deinem echten SchlÃ¼ssel!

---

### 6. API-Key besorgen

#### **Option A: OpenAI (kostenpflichtig, beste QualitÃ¤t)**
1. Gehe zu https://platform.openai.com/api-keys
2. Erstelle neuen API-Key
3. Kopiere in `.env` â†’ `OPENAI_API_KEY`

#### **Option B: Lokale Alternative (kostenlos, Offline)**
Nutze **Ollama** (lokal, keine API-Keys nÃ¶tig):

```bash
# 1. Ollama installieren: https://ollama.com/download
# 2. Model herunterladen
ollama pull llama3.2-vision

# 3. Server starten
ollama serve  # lÃ¤uft auf Port 11434
```

**`.env` anpassen:**
```properties
OPENAI_BASE_URL=http://localhost:11434/v1
OPENAI_MODEL=llama3.2-vision
OPENAI_API_KEY=dummy  # beliebiger Wert
```

---

## ğŸ® Nutzung

### Starten

```bash
source .venv/Scripts/activate  # Git Bash
python assistant.py
```

**Erwartete Ausgabe:**
```
============================================================
ğŸ™ï¸  Alloy Voice Assistant
============================================================
âœ… Webcam gestartet (Index: 0)
âœ… LLM-Agent geladen (Model: gpt-4o)
ğŸ¤ Kalibriere Mikrofon...
âœ… STT bereit (Whisper: base)
ğŸŒ Aktuelle Sprache: Ğ ÑƒÑÑĞºĞ¸Ğ¹
============================================================

ğŸ“‹ Hotkeys:
  [1] = Ğ ÑƒÑÑĞºĞ¸Ğ¹ (Russian)
  [2] = Deutsch (German)
  [q] / [ESC] = Beenden
```

---

### Hotkeys (wÃ¤hrend Laufzeit)

| Taste | Aktion |
|-------|--------|
| **`1`** | Wechsel zu Russisch |
| **`2`** | Wechsel zu Deutsch |
| **`q`** / **ESC** | Beenden |

---

### Beispiel-Prompts

#### **Russisch**
- *"ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, ĞºĞ°Ğº Ğ´ĞµĞ»Ğ°?"* â†’ Grundlegende Konversation
- *"ĞšĞ°ĞºĞ°Ñ Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ğ° Ğ² ĞœĞ¾ÑĞºĞ²Ğµ?"* â†’ Nutzt Wetter-Tool
- *"ĞĞ°Ğ¹Ğ´Ğ¸ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸ Ğ¿Ñ€Ğ¾ Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚ 2025"* â†’ Nutzt Web-Suche
- *"Ğ§Ñ‚Ğ¾ Ñ‚Ñ‹ Ğ²Ğ¸Ğ´Ğ¸ÑˆÑŒ Ğ½Ğ° ĞºĞ°Ğ¼ĞµÑ€Ğµ?"* â†’ Beschreibt Webcam-Bild
- *"ĞšĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ñ‡Ğ°Ñ?"* â†’ Nutzt Zeit-Tool
- *"Ğ¡ĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ±ÑƒĞ´ĞµÑ‚ 15 ÑƒĞ¼Ğ½Ğ¾Ğ¶Ğ¸Ñ‚ÑŒ Ğ½Ğ° 7?"* â†’ Nutzt Rechner-Tool

#### **Deutsch**
- *"Hallo, wie geht es dir?"* â†’ Grundlegende Konversation
- *"Wie ist das Wetter in Berlin?"* â†’ Nutzt Wetter-Tool
- *"Suche nach KI-News 2025"* â†’ Nutzt Web-Suche
- *"Was siehst du vor der Kamera?"* â†’ Beschreibt Webcam-Bild
- *"Wie spÃ¤t ist es?"* â†’ Nutzt Zeit-Tool
- *"Rechne 144 geteilt durch 12"* â†’ Nutzt Rechner-Tool

---

## ğŸ› ï¸ Konfiguration

### Audio-Device finden

```bash
python list_audio_devices.py
```

**Output-Beispiel:**
```
============================================================
Available Audio Output Devices:
============================================================

[0] Microsoft Sound Mapper - Output
    Host API: MME
    Sample Rate: 44100 Hz
    Channels: 2 â† DEFAULT

[3] Lautsprecher (Realtek High Definition Audio)
    Host API: MME
    Sample Rate: 48000 Hz
    Channels: 2
============================================================
```

**In `.env` setzen:**
```properties
AUDIO_OUTPUT_DEVICE=3
```

---

### Webcam-Index finden

```bash
python -c "import cv2; [print(f'Camera {i}: Available') for i in range(10) if cv2.VideoCapture(i).isOpened()]"
```

**Output-Beispiel:**
```
Camera 0: Available
Camera 1: Available
```

**In `.env` setzen:**
```properties
CAMERA_INDEX=1  # fÃ¼r externe USB-Kamera
```

---

### Neue Sprache hinzufÃ¼gen

1. **Piper-Model herunterladen** (https://huggingface.co/rhasspy/piper-voices)
2. **In `assistant.py` â†’ `LANGUAGE_CONFIG` hinzufÃ¼gen:**

```python
"en": {
    "whisper_lang": "en",
    "response_lang": "English",
    "piper_model": "models/piper/en/en_US/lessac/medium/en_US-lessac-medium.onnx",
    "display_name": "English"
}
```

3. **In `.env` definieren:**
```properties
PIPER_MODEL_EN=models/piper/en/en_US/lessac/medium/en_US-lessac-medium.onnx
```

4. **Hotkey in `main()` hinzufÃ¼gen:**
```python
elif key == ord("3"):  # Englisch
    assistant.set_language("en")
```

---

### Tools erweitern

**Beispiel: Wikipedia-Tool hinzufÃ¼gen**

In `tools.py`:
```python
def wikipedia_tool(query: str) -> str:
    """Sucht in Wikipedia nach Informationen."""
    import wikipedia
    wikipedia.set_lang("de")  # oder "ru", "en"
    try:
        return wikipedia.summary(query, sentences=3)
    except Exception as e:
        return f"Wikipedia-Fehler: {e}"

DEFAULT_TOOLS.append(Tool(
    name="wikipedia",
    func=wikipedia_tool,
    description="Sucht in Wikipedia nach Fakten und Definitionen. Input: Suchbegriff."
))
```

---

## ğŸ› Troubleshooting

### Problem: `ModuleNotFoundError: No module named 'piper'`
**LÃ¶sung:**
```bash
pip install piper-tts~=1.3
```

---

### Problem: `pyaudio` Installation schlÃ¤gt fehl
**LÃ¶sung (Windows):**
```bash
pip install pipwin
pipwin install pyaudio
```

**LÃ¶sung (Linux/Ubuntu):**
```bash
sudo apt install portaudio19-dev python3-pyaudio
pip install pyaudio
```

---

### Problem: Webcam wird nicht erkannt
**LÃ¶sung:**
```bash
# VerfÃ¼gbare Kameras auflisten
python -c "import cv2; [print(f'Camera {i}: Available') for i in range(10) if cv2.VideoCapture(i).isOpened()]"

# Index in .env setzen
echo "CAMERA_INDEX=1" >> .env
```

---

### Problem: Kein Audio-Output (TTS stumm)
**LÃ¶sung:**
```bash
# Audio-Devices auflisten
python list_audio_devices.py

# Device in .env setzen (z.B. 3 fÃ¼r Lautsprecher)
echo "AUDIO_OUTPUT_DEVICE=3" >> .env
```

---

### Problem: `RuntimeWarning: Parameters {'stop'} should be specified`
**Status:** âœ… Bereits behoben in v1.0 (`stop=[]` in ChatOpenAI-Konstruktor)

---

### Problem: Agent nutzt veraltete Jahreszahl (2023)
**Status:** âœ… Bereits behoben â€“ System-Prompt enthÃ¤lt: `TODAY'S DATE AND TIME: 19.10.2025`

---

### Problem: Vision funktioniert nicht
**Ursachen:**
1. Modell unterstÃ¼tzt keine Vision (z.B. `gpt-3.5-turbo`)
2. Webcam liefert keine Bilder

**LÃ¶sung:**
```bash
# 1. PrÃ¼fe Model in .env
OPENAI_MODEL=gpt-4o  # âœ… unterstÃ¼tzt Vision
# OPENAI_MODEL=gpt-3.5-turbo  # âŒ keine Vision

# 2. Teste Webcam
python -c "import cv2; cap=cv2.VideoCapture(0); print('OK' if cap.read()[0] else 'FEHLER')"
```

---

## ğŸ“¦ Projekt-Struktur

```
alloy-voice-assistant/
â”œâ”€â”€ assistant.py              # Hauptprogramm (Webcam + STT + Agent + TTS)
â”œâ”€â”€ tools.py                  # Wiederverwendbare LangChain-Tools
â”œâ”€â”€ list_audio_devices.py     # Helper: Audio-Devices auflisten
â”œâ”€â”€ requirements.txt          # Python-Dependencies
â”œâ”€â”€ .env.example              # Beispiel-Konfiguration
â”œâ”€â”€ .env                      # Deine Konfiguration (GIT-IGNORED!)
â”œâ”€â”€ .gitignore                # Git-Exclude-Rules
â”œâ”€â”€ models/                   # TTS-Modelle (GIT-IGNORED!)
â”‚   â””â”€â”€ piper/
â”‚       â”œâ”€â”€ ru/               # Russische Stimmen
â”‚       â””â”€â”€ de/               # Deutsche Stimmen
â””â”€â”€ README.md                 # Diese Datei
```

---

## ğŸ”’ Sicherheit

- âŒ **Committen Sie NIEMALS `.env`** (enthÃ¤lt API-Keys)
- âœ… `.env` ist bereits in `.gitignore`
- âœ… Nutzen Sie starke, einzigartige API-Keys
- âš ï¸ `calculator`-Tool nutzt `eval()` â†’ nur fÃ¼r vertrauenswÃ¼rdige Inputs!
- ğŸ” Empfehlung: Nutzen Sie separate API-Keys fÃ¼r Entwicklung/Production

---

## ğŸ“„ Lizenz

MIT License

```
MIT License

Copyright (c) 2025 [Dein Name]

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---

## ğŸ™ Credits

- **OpenAI Whisper** (STT): https://github.com/openai/whisper
- **Piper TTS**: https://github.com/rhasspy/piper
- **LangChain**: https://python.langchain.com/
- **wttr.in** (Wetter-API): https://wttr.in/
- **DuckDuckGo Search**: https://pypi.org/project/ddgs/
- **OpenCV**: https://opencv.org/

---

## ğŸ†˜ Support

Bei Problemen:
1. âœ… PrÃ¼fe [Troubleshooting](#-troubleshooting)
2. ğŸ› Ã–ffne ein Issue auf GitHub
3. ğŸ“§ Kontakt: your.email@example.com

---

## ğŸš§ Roadmap

- [ ] **Englisch-Support** (in Arbeit)
- [ ] Wikipedia-Tool
- [ ] Kalender-Integration (Google Calendar)
- [ ] Smart-Home-Steuerung (Home Assistant API)
- [ ] Multi-User-Support (Stimmerkennung)
- [ ] Dockerisierung
- [ ] Web-UI (Flask/Gradio)
- [ ] Persistent Chat-History (SQLite)
- [ ] RAG-Integration (PDFs/Docs durchsuchen)

---

## ğŸ“Š Changelog

### v1.0.0 (2025-10-19)
- âœ¨ Initial Release
- âœ… Multimodal Agent (Text + Vision)
- âœ… Russisch/Deutsch-Support
- âœ… Lokale TTS (Piper)
- âœ… 4 Tools (Web, Wetter, Zeit, Rechner)

---

**Version:** 1.0.0 | **Letztes Update:** 19.10.2025